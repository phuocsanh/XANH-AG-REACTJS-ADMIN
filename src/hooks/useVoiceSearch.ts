import { useState, useEffect, useCallback, useRef } from 'react'

/**
 * Custom hook Ä‘á»ƒ xá»­ lÃ½ tÃ¬m kiáº¿m báº±ng giá»ng nÃ³i
 * Sá»­ dá»¥ng Web Speech API (SpeechRecognition)
 * Há»— trá»£ tiáº¿ng Viá»‡t
 */

// Type definition cho Web Speech API
declare global {
  interface Window {
    SpeechRecognition: any
    webkitSpeechRecognition: any
  }
}

// Kiá»ƒm tra browser cÃ³ há»— trá»£ Speech Recognition khÃ´ng
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition

interface UseVoiceSearchOptions {
  lang?: string // NgÃ´n ngá»¯ (máº·c Ä‘á»‹nh: 'vi-VN')
  continuous?: boolean // Ghi Ã¢m liÃªn tá»¥c hay khÃ´ng
  interimResults?: boolean // Hiá»ƒn thá»‹ káº¿t quáº£ táº¡m thá»i
  maxAlternatives?: number // Sá»‘ lÆ°á»£ng káº¿t quáº£ thay tháº¿
  onTranscript?: (text: string) => void // Callback khi cÃ³ káº¿t quáº£
  onError?: (error: string) => void // Callback khi cÃ³ lá»—i
}

interface UseVoiceSearchReturn {
  isListening: boolean // Äang ghi Ã¢m
  transcript: string // VÄƒn báº£n nháº­n Ä‘Æ°á»£c
  interimTranscript: string // VÄƒn báº£n táº¡m thá»i (Ä‘ang nÃ³i)
  error: string | null // Lá»—i náº¿u cÃ³
  isSupported: boolean // TrÃ¬nh duyá»‡t cÃ³ há»— trá»£ khÃ´ng
  startListening: () => void // Báº¯t Ä‘áº§u ghi Ã¢m
  stopListening: () => void // Dá»«ng ghi Ã¢m
  resetTranscript: () => void // Reset vÄƒn báº£n
}

export const useVoiceSearch = (options: UseVoiceSearchOptions = {}): UseVoiceSearchReturn => {
  const {
    lang = 'vi-VN',
    continuous = false,
    interimResults = true,
    maxAlternatives = 1,
    onTranscript,
    onError,
  } = options

  const [isListening, setIsListening] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [interimTranscript, setInterimTranscript] = useState('')
  const [error, setError] = useState<string | null>(null)
  const recognitionRef = useRef<any>(null)
  const silenceTimeoutRef = useRef<NodeJS.Timeout | null>(null) // Timeout Ä‘á»ƒ auto-stop
  
  // DÃ¹ng ref Ä‘á»ƒ lÆ°u callbacks, trÃ¡nh re-render
  const onTranscriptRef = useRef(onTranscript)
  const onErrorRef = useRef(onError)
  
  // Update refs khi callbacks thay Ä‘á»•i
  useEffect(() => {
    onTranscriptRef.current = onTranscript
    onErrorRef.current = onError
  }, [onTranscript, onError])

  // Kiá»ƒm tra browser support
  const isSupported = typeof SpeechRecognition !== 'undefined'

  // Khá»Ÿi táº¡o SpeechRecognition
  useEffect(() => {
    console.log('ğŸ”§ Initializing SpeechRecognition...')
    console.log('isSupported:', isSupported)
    console.log('SpeechRecognition:', SpeechRecognition)
    
    if (!isSupported) {
      const errorMsg = 'TrÃ¬nh duyá»‡t khÃ´ng há»— trá»£ tÃ¬m kiáº¿m báº±ng giá»ng nÃ³i. Vui lÃ²ng sá»­ dá»¥ng Chrome hoáº·c Edge.'
      console.error('âŒ', errorMsg)
      setError(errorMsg)
      return
    }

    const recognition = new SpeechRecognition()
    console.log('âœ… SpeechRecognition instance created:', recognition)
    
    recognition.lang = lang
    recognition.continuous = continuous
    recognition.interimResults = interimResults
    recognition.maxAlternatives = maxAlternatives
    
    console.log('âš™ï¸ Recognition config:', {
      lang,
      continuous,
      interimResults,
      maxAlternatives
    })
    
    // Flag Ä‘á»ƒ track xem Ä‘Ã£ nÃ³i láº§n Ä‘áº§u chÆ°a
    let hasSpokenOnce = false
    
    // Helper function Ä‘á»ƒ reset timeout (inline)
    const resetSilenceTimeout = () => {
      // Clear timeout cÅ©
      if (silenceTimeoutRef.current) {
        clearTimeout(silenceTimeoutRef.current)
      }
      
      // Chá»‰ set timeout náº¿u Ä‘Ã£ nÃ³i láº§n Ä‘áº§u
      if (hasSpokenOnce) {
        // Set timeout má»›i: sau 1s khÃ´ng cÃ³ giá»ng nÃ³i â†’ auto stop
        silenceTimeoutRef.current = setTimeout(() => {
          console.log('â±ï¸ 1s silence detected, auto-stopping...')
          if (recognitionRef.current) {
            recognitionRef.current.stop()
          }
        }, 1000) // Giáº£m tá»« 1500ms xuá»‘ng 1000ms
      }
    }

    // Xá»­ lÃ½ káº¿t quáº£
    recognition.onresult = (event: any) => {
      console.log('ğŸ¤ onresult event:', event)
      
      // ÄÃ¡nh dáº¥u Ä‘Ã£ nÃ³i láº§n Ä‘áº§u
      if (!hasSpokenOnce) {
        hasSpokenOnce = true
        console.log('âœ… First speech detected, timeout will start after this')
      }
      
      // Reset timeout má»—i khi cÃ³ giá»ng nÃ³i
      resetSilenceTimeout()
      
      let finalTranscript = ''
      let interimText = ''

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcriptPart = event.results[i][0].transcript
        console.log(`Result ${i}:`, {
          transcript: transcriptPart,
          isFinal: event.results[i].isFinal,
          confidence: event.results[i][0].confidence
        })
        
        if (event.results[i].isFinal) {
          finalTranscript += transcriptPart
        } else {
          interimText += transcriptPart
        }
      }

      console.log('ğŸ“ Final transcript:', finalTranscript)
      console.log('ğŸ“ Interim transcript:', interimText)

      if (finalTranscript) {
        setTranscript(finalTranscript)
        setInterimTranscript('')
        console.log('âœ… Calling onTranscript callback with:', finalTranscript)
        if (onTranscriptRef.current) {
          onTranscriptRef.current(finalTranscript)
        }
      } else {
        setInterimTranscript(interimText)
      }
    }

    // Xá»­ lÃ½ lá»—i
    recognition.onerror = (event: any) => {
      console.error('âŒ Speech recognition error:', event.error, event)
      
      // Clear timeout khi cÃ³ lá»—i
      if (silenceTimeoutRef.current) {
        clearTimeout(silenceTimeoutRef.current)
      }
      
      // Náº¿u lá»—i "no-speech", khÃ´ng hiá»ƒn thá»‹ lá»—i, chá»‰ log
      if (event.error === 'no-speech') {
        console.warn('âš ï¸ No speech detected, but keeping recognition active...')
        // KhÃ´ng set error, khÃ´ng stop listening
        // Recognition sáº½ tá»± Ä‘á»™ng tiáº¿p tá»¥c láº¯ng nghe
        return
      }
      
      let errorMessage = 'ÄÃ£ xáº£y ra lá»—i khi ghi Ã¢m'
      
      switch (event.error) {
        case 'audio-capture':
          errorMessage = 'KhÃ´ng tÃ¬m tháº¥y microphone. Vui lÃ²ng kiá»ƒm tra thiáº¿t bá»‹.'
          break
        case 'not-allowed':
          errorMessage = 'Quyá»n truy cáº­p microphone bá»‹ tá»« chá»‘i. Vui lÃ²ng cho phÃ©p trong cÃ i Ä‘áº·t trÃ¬nh duyá»‡t.'
          break
        case 'network':
          errorMessage = 'Lá»—i máº¡ng. Vui lÃ²ng kiá»ƒm tra káº¿t ná»‘i internet.'
          break
        case 'aborted':
          // NgÆ°á»i dÃ¹ng tá»± dá»«ng, khÃ´ng hiá»ƒn thá»‹ lá»—i
          errorMessage = ''
          break
        default:
          errorMessage = `Lá»—i: ${event.error}`
      }

      if (errorMessage) {
        setError(errorMessage)
        if (onErrorRef.current) {
          onErrorRef.current(errorMessage)
        }
      }
      setIsListening(false)
    }

    // Xá»­ lÃ½ khi káº¿t thÃºc
    recognition.onend = () => {
      console.log('ğŸ›‘ Speech recognition ended')
      
      // Clear timeout
      if (silenceTimeoutRef.current) {
        clearTimeout(silenceTimeoutRef.current)
      }
      
      setIsListening(false)
      setInterimTranscript('')
    }

    // Xá»­ lÃ½ khi báº¯t Ä‘áº§u
    recognition.onstart = () => {
      console.log('â–¶ï¸ Speech recognition started')
      setIsListening(true)
      setError(null)
      // KhÃ´ng báº¯t Ä‘áº§u timeout ngay - chá»‰ báº¯t Ä‘áº§u sau khi Ä‘Ã£ nÃ³i láº§n Ä‘áº§u
    }

    recognitionRef.current = recognition

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.abort()
      }
      if (silenceTimeoutRef.current) {
        clearTimeout(silenceTimeoutRef.current)
      }
    }
  }, [isSupported, lang, continuous, interimResults, maxAlternatives]) // Loáº¡i bá» resetSilenceTimeout

  // Báº¯t Ä‘áº§u ghi Ã¢m
  const startListening = useCallback(() => {
    console.log('ğŸ™ï¸ startListening called')
    console.log('isSupported:', isSupported)
    console.log('isListening:', isListening)
    console.log('recognitionRef.current:', recognitionRef.current)
    
    if (!isSupported) {
      console.error('âŒ Browser not supported')
      setError('TrÃ¬nh duyá»‡t khÃ´ng há»— trá»£ tÃ¬m kiáº¿m báº±ng giá»ng nÃ³i.')
      return
    }

    if (recognitionRef.current && !isListening) {
      try {
        console.log('ğŸš€ Starting recognition...')
        setError(null)
        setTranscript('')
        setInterimTranscript('')
        recognitionRef.current.start()
        console.log('âœ… Recognition started successfully')
      } catch (err) {
        console.error('âŒ Error starting recognition:', err)
        setError('KhÃ´ng thá»ƒ báº¯t Ä‘áº§u ghi Ã¢m. Vui lÃ²ng thá»­ láº¡i.')
      }
    } else {
      console.warn('âš ï¸ Cannot start: recognitionRef or already listening')
    }
  }, [isSupported, isListening])

  // Dá»«ng ghi Ã¢m
  const stopListening = useCallback(() => {
    if (recognitionRef.current && isListening) {
      recognitionRef.current.stop()
    }
  }, [isListening])

  // Reset transcript
  const resetTranscript = useCallback(() => {
    setTranscript('')
    setInterimTranscript('')
    setError(null)
  }, [])

  return {
    isListening,
    transcript,
    interimTranscript,
    error,
    isSupported,
    startListening,
    stopListening,
    resetTranscript,
  }
}
